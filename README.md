# ASL_Recognition

We will be creating an ASL interpreter capable of translating any sign of the alphabet into text format, essentially making a real time translator. By taking advantage of TensorFlow and its ability to create easy to use Machine Learning; We will be able to create an environment in which the camera of your desktop or laptop is used in order to translate American Sign Language signs (ASL) efficiently all in real time!

Before we start, first we need to make sure we have the necessary equipment installed in our computer or laptop to make this interactive program:
Download latest version of python
Download the latest version of Jupyter (need to use Jupyter Notebook)
Download anaconda (for the machine learning part of the application)
Install “labelImg” program from the following git repository:
https://github.com/HumanSignal/labelImg


Note: knowing how to use JSON files will also make this project easier to understand and modify to your liking. If you are not familiar with such files, don't worry; We will go step by step in order to ensure everyone understands!


Once you have installed all the applications from above, open command line (cmd) and type in the following command like:
“jupyter notebook”
NOTE: This will open up a local host in Jupyter notebook in order for us to start coding our program.
(SHOW CODE)

Within jupyter notebook, write the following: 
(SHOW CODE)

Start collecting pictures of the signs placed in the array “label”

Open up the “labelImg” program downloaded from above by ding the following:
(Running labelImg)
STEP1:
cd "C:\Users\halo2\RealTimeObjectDetection\labelapp\Tensorflow\labelimgdown"

STEP2:
pyrcc5 -o libs/resources.py resources.qrc

STEP3:
python labelImg.py


Once all the pictures are collected...
